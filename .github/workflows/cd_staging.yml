name: CD to Staging

on:
  pull_request:
    branches:  
      - 'main'         


jobs:
  cd-staging:

    runs-on: ubuntu-latest
    strategy:
      max-parallel: 4

    env:
      DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }} 
      DATABRICKS_TOKEN:  ${{ secrets.DATABRICKS_TOKEN }}

    steps:
      - uses: actions/checkout@v2
        with:
          fetch-depth: 0  # Shallow clones should be disabled for a better relevancy of analysis   

      - name: Get the version number
        run: |
          cat databricks_poc_template/__init__.py
          s=$(<databricks_poc_template/__init__.py)
          s=${s#*'"'}; 
          version=${s%'"'*}
          version_print=v"$version"
          echo Running CD to Staging for version $version_print             

      - name: Set up Python 3.9
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'
          cache: 'pip' # caching pip dependencies
          cache-dependency-path: setup.py

      - name: Install pip
        run: |
          python -m pip install --upgrade pip

      - name: Install dependencies and project in dev mode
        run: |
          pip install -e ".[local,test]"

      - name: Deploy the training job to STAGING (as retraining pipeline job)
        run: |
          make train_workflow_staging

      # TODO: HERE DO THE DEPLOYMENT TO UAT ONLY IF TRAINING IN STAGING SUCCESSFUL (i.e. threshold met) !!!

      - name: Deploy the inference job to UAT
        run: |
          make inference_uat

      - name: Deploy the monitoring job to UAT
        run: |
          make monitoring_uat               
